{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5666,"status":"ok","timestamp":1670495947793,"user":{"displayName":"Ramsha Ghulam Mustafa","userId":"01894469828690764953"},"user_tz":-300},"id":"6-lN63sygNtQ","outputId":"5951e0a3-4ddd-48d7-ef5c-076c80b1dfd9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3489,"status":"ok","timestamp":1670557498173,"user":{"displayName":"Ramsha Ghulam Mustafa","userId":"01894469828690764953"},"user_tz":-300},"id":"tHJ0xaD8ge25","outputId":"9e3faac1-3354-405d-cb7e-e99ea60a7488"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: keras-nlp in /usr/local/lib/python3.8/dist-packages (0.3.1)\n","Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.8/dist-packages (from keras-nlp) (2.9.0)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (from keras-nlp) (2.9.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from keras-nlp) (21.3)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from keras-nlp) (1.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from keras-nlp) (1.21.6)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->keras-nlp) (3.0.9)\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3021, in _dep_map\n","    return self.__dep_map\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2815, in __getattr__\n","    raise AttributeError(attr)\n","AttributeError: _DistInfoDistribution__dep_map\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 180, in _main\n","    status = self.run(options, args)\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/req_command.py\", line 199, in wrapper\n","    return func(self, options, args)\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/commands/install.py\", line 318, in run\n","    requirement_set = resolver.resolve(\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 127, in resolve\n","    result = self._result = resolver.resolve(\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 473, in resolve\n","    state = resolution.resolve(requirements, max_rounds=max_rounds)\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 367, in resolve\n","    failure_causes = self._attempt_to_pin_criterion(name)\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 213, in _attempt_to_pin_criterion\n","    criteria = self._get_criteria_to_update(candidate)\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 202, in _get_criteria_to_update\n","    for r in self._p.get_dependencies(candidate=candidate):\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/resolution/resolvelib/provider.py\", line 175, in get_dependencies\n","    return [r for r in candidate.iter_dependencies(with_requires) if r is not None]\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/resolution/resolvelib/provider.py\", line 175, in <listcomp>\n","    return [r for r in candidate.iter_dependencies(with_requires) if r is not None]\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 419, in iter_dependencies\n","    for r in self.dist.requires():\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2736, in requires\n","    dm = self._dep_map\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3023, in _dep_map\n","    self.__dep_map = self._compute_dependencies()\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3033, in _compute_dependencies\n","    reqs.extend(parse_requirements(req))\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3094, in parse_requirements\n","    yield Requirement(line)\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3101, in __init__\n","    super(Requirement, self).__init__(requirement_string)\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/packaging/requirements.py\", line 113, in __init__\n","    req = REQUIREMENT.parseString(requirement_string)\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 1943, in parseString\n","    loc, tokens = self._parse(instring, 0)\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, preloc, doActions)\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 4069, in parseImpl\n","    loc, exprtokens = e._parse(instring, loc, doActions)\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, preloc, doActions)\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 4254, in parseImpl\n","    ret = e._parse(instring, loc, doActions)\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, preloc, doActions)\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 4052, in parseImpl\n","    loc, resultlist = self.exprs[0]._parse(instring, loc, doActions, callPreParse=False)\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, preloc, doActions)\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 4069, in parseImpl\n","    loc, exprtokens = e._parse(instring, loc, doActions)\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, preloc, doActions)\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 4849, in parseImpl\n","    loc, tokens = self.expr._parse(instring, loc, doActions, callPreParse=False)\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, preloc, doActions)\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 4254, in parseImpl\n","    ret = e._parse(instring, loc, doActions)\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, preloc, doActions)\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 4069, in parseImpl\n","    loc, exprtokens = e._parse(instring, loc, doActions)\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, preloc, doActions)\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 4462, in parseImpl\n","    return self.expr._parse(instring, loc, doActions, callPreParse=False)\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, preloc, doActions)\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 4069, in parseImpl\n","    loc, exprtokens = e._parse(instring, loc, doActions)\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, preloc, doActions)\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 4781, in parseImpl\n","    return super(ZeroOrMore, self).parseImpl(instring, loc, doActions)\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/pip3\", line 8, in <module>\n","    sys.exit(main())\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/main.py\", line 71, in main\n","    return command.main(cmd_args)\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 104, in main\n","    return self._main(args)\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 212, in _main\n","    logger.critical(\"Operation cancelled by user\")\n","  File \"/usr/lib/python3.8/logging/__init__.py\", line 1493, in critical\n","    self._log(CRITICAL, msg, args, **kwargs)\n","  File \"/usr/lib/python3.8/logging/__init__.py\", line 1587, in _log\n","    record = self.makeRecord(self.name, level, fn, lno, msg, args,\n","  File \"/usr/lib/python3.8/logging/__init__.py\", line 1556, in makeRecord\n","    rv = _logRecordFactory(name, level, fn, lno, msg, args, exc_info, func,\n","  File \"/usr/lib/python3.8/logging/__init__.py\", line 322, in __init__\n","    self.filename = os.path.basename(pathname)\n","  File \"/usr/lib/python3.8/posixpath.py\", line 144, in basename\n","    i = p.rfind(sep) + 1\n","KeyboardInterrupt\n","^C\n"]}],"source":["!pip install -q rouge-score\n","!pip install keras-nlp"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g55ddVDSgir6"},"outputs":[],"source":["import keras_nlp\n","import numpy as np\n","import pandas as pd\n","import pathlib\n","import random\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from tensorflow import keras\n","from keras.models import  model_from_json\n","from tensorflow_text.tools.wordpiece_vocab import bert_vocab_from_dataset as bert_vocab"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZJdZh2KDgmm4"},"outputs":[],"source":["BATCH_SIZE = 128\n","EPOCHS = 5  # This should be at least 10 for convergence\n","MAX_SEQUENCE_LENGTH = 20\n","ENG_VOCAB_SIZE = 104890\n","SND_VOCAB_SIZE = 104890\n","\n","EMBED_DIM = 256\n","INTERMEDIATE_DIM = 2048\n","NUM_HEADS = 8"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"saQGjRmxgouZ"},"outputs":[],"source":["data = pd.read_csv('/content/drive/MyDrive/English-to-Sindhi Translation/english-sindhi2.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LQIXjh8njPzs"},"outputs":[],"source":["text_pairs = data.values.tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1670490315118,"user":{"displayName":"Ramsha Ghulam Mustafa","userId":"01894469828690764953"},"user_tz":-300},"id":"KkBBQSurkdNw","outputId":"d91817cd-d43f-4561-c9c7-43f829b2aab7"},"outputs":[{"name":"stdout","output_type":"stream","text":["104890 total pairs\n","73424 training pairs\n","15733 validation pairs\n","15733 test pairs\n"]}],"source":["random.shuffle(text_pairs)\n","num_val_samples = int(0.15 * len(text_pairs))\n","num_train_samples = len(text_pairs) - 2 * num_val_samples\n","train_pairs = text_pairs[:num_train_samples]\n","val_pairs = text_pairs[num_train_samples : num_train_samples + num_val_samples]\n","test_pairs = text_pairs[num_train_samples + num_val_samples :]\n","\n","print(f\"{len(text_pairs)} total pairs\")\n","print(f\"{len(train_pairs)} training pairs\")\n","print(f\"{len(val_pairs)} validation pairs\")\n","print(f\"{len(test_pairs)} test pairs\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UntAAOLho29c"},"outputs":[],"source":["def train_word_piece(text_samples, vocab_size, reserved_tokens):\n","    bert_vocab_args = dict(\n","        # The target vocabulary size\n","        vocab_size=vocab_size,\n","        # Reserved tokens that must be included in the vocabulary\n","        reserved_tokens=reserved_tokens,\n","        # Arguments for `text.BertTokenizer`\n","        bert_tokenizer_params={\"lower_case\": True},\n","    )\n","\n","    word_piece_ds = tf.data.Dataset.from_tensor_slices(text_samples)\n","    vocab = bert_vocab.bert_vocab_from_dataset(\n","        word_piece_ds.batch(1000).prefetch(2), **bert_vocab_args\n","    )\n","    return vocab"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HBNHR9pio4td"},"outputs":[],"source":["def train_word_piece(text_samples, vocab_size, reserved_tokens):\n","    bert_vocab_args = dict(\n","        # The target vocabulary size\n","        vocab_size=vocab_size,\n","        # Reserved tokens that must be included in the vocabulary\n","        reserved_tokens=reserved_tokens,\n","        # Arguments for `text.BertTokenizer`\n","        bert_tokenizer_params={\"lower_case\": True},\n","    )\n","\n","    word_piece_ds = tf.data.Dataset.from_tensor_slices(text_samples)\n","    vocab = bert_vocab.bert_vocab_from_dataset(\n","        word_piece_ds.batch(1000).prefetch(2), **bert_vocab_args\n","    )\n","    return vocab"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kgRNTAeUo_3D"},"outputs":[],"source":["reserved_tokens = [\"[PAD]\", \"[UNK]\", \"[START]\", \"[END]\"]\n","\n","eng_samples = [text_pair[0] for text_pair in train_pairs]\n","eng_vocab = train_word_piece(eng_samples, ENG_VOCAB_SIZE, reserved_tokens)\n","\n","snd_samples = [text_pair[1] for text_pair in train_pairs]\n","snd_vocab = train_word_piece(snd_samples, SND_VOCAB_SIZE, reserved_tokens)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":50,"status":"ok","timestamp":1670487122597,"user":{"displayName":"Ramsha Ghulam Mustafa","userId":"01894469828690764953"},"user_tz":-300},"id":"2rOrwggXpEjj","outputId":"f700453b-ea21-4a30-9d3a-ebed9d798b5b"},"outputs":[{"name":"stdout","output_type":"stream","text":["English Tokens:  ['out', 'if', 'just', 'one', 'didnt', 'going', 'an', 'from', 'would', 'good']\n","Sindhi Tokens:  ['ے', '۽', '۾', 'اهي', 'کي', 'مون', 'مان', 'توهان', 'جي', 'ته']\n"]}],"source":["print(\"English Tokens: \", eng_vocab[100:110])\n","print(\"Sindhi Tokens: \", snd_vocab[100:110])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6Gmxcvl7wVER"},"outputs":[],"source":["eng_tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n","    vocabulary=eng_vocab, lowercase=False\n",")\n","snd_tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n","    vocabulary=snd_vocab, lowercase=False\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31,"status":"ok","timestamp":1670487122600,"user":{"displayName":"Ramsha Ghulam Mustafa","userId":"01894469828690764953"},"user_tz":-300},"id":"QZP0hGXmxDcG","outputId":"7e1df5ee-4360-4d38-d78e-3e47a20c25bb"},"outputs":[{"name":"stdout","output_type":"stream","text":["English sentence:  i dont feel like taking a walk this morning\n","Tokens:  tf.Tensor([ 23  57 190  70 562  15 348  51 277], shape=(9,), dtype=int32)\n","Recovered text after detokenizing:  tf.Tensor(b'i dont feel like taking a walk this morning', shape=(), dtype=string)\n","\n","Sindhi sentence:  مون کي اڄ صبح سير ڪرڻ لاء دل نه ٿو لڳي\n","Tokens:  tf.Tensor([ 105  104  190  342 1234  126  124  691  110  111  229], shape=(11,), dtype=int32)\n","Recovered text after detokenizing:  tf.Tensor(b'\\xd9\\x85\\xd9\\x88\\xd9\\x86 \\xda\\xa9\\xd9\\x8a \\xd8\\xa7\\xda\\x84 \\xd8\\xb5\\xd8\\xa8\\xd8\\xad \\xd8\\xb3\\xd9\\x8a\\xd8\\xb1 \\xda\\xaa\\xd8\\xb1\\xda\\xbb \\xd9\\x84\\xd8\\xa7\\xd8\\xa1 \\xd8\\xaf\\xd9\\x84 \\xd9\\x86\\xd9\\x87 \\xd9\\xbf\\xd9\\x88 \\xd9\\x84\\xda\\xb3\\xd9\\x8a', shape=(), dtype=string)\n"]}],"source":["eng_input_ex = text_pairs[0][0]\n","eng_tokens_ex = eng_tokenizer.tokenize(eng_input_ex)\n","print(\"English sentence: \", eng_input_ex)\n","print(\"Tokens: \", eng_tokens_ex)\n","print(\"Recovered text after detokenizing: \", eng_tokenizer.detokenize(eng_tokens_ex))\n","\n","print()\n","\n","snd_input_ex = text_pairs[0][1]\n","snd_tokens_ex = snd_tokenizer.tokenize(snd_input_ex)\n","print(\"Sindhi sentence: \", snd_input_ex)\n","print(\"Tokens: \", snd_tokens_ex)\n","print(\"Recovered text after detokenizing: \", snd_tokenizer.detokenize(snd_tokens_ex))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z9hhFmCDxVoc"},"outputs":[],"source":["def preprocess_batch(eng, snd):\n","    batch_size = tf.shape(snd)[0]\n","\n","    eng = eng_tokenizer(eng)\n","    snd = snd_tokenizer(snd)\n","\n","    # Pad `eng` to `MAX_SEQUENCE_LENGTH`.\n","    eng_start_end_packer = keras_nlp.layers.StartEndPacker(\n","        sequence_length=MAX_SEQUENCE_LENGTH,\n","        pad_value=eng_tokenizer.token_to_id(\"[PAD]\"),\n","    )\n","    eng = eng_start_end_packer(eng)\n","\n","    # Add special tokens (`\"[START]\"` and `\"[END]\"`) to `snd` and pad it as well.\n","    snd_start_end_packer = keras_nlp.layers.StartEndPacker(\n","        sequence_length=MAX_SEQUENCE_LENGTH + 1,\n","        start_value=snd_tokenizer.token_to_id(\"[START]\"),\n","        end_value=snd_tokenizer.token_to_id(\"[END]\"),\n","        pad_value=snd_tokenizer.token_to_id(\"[PAD]\"),\n","    )\n","    snd = snd_start_end_packer(snd)\n","\n","    return (\n","        {\n","            \"encoder_inputs\": eng,\n","            \"decoder_inputs\": snd[:, :-1],\n","        },\n","        snd[:, 1:],\n","    )\n","\n","\n","def make_dataset(pairs):\n","    eng_texts, snd_texts = zip(*pairs)\n","    eng_texts = list(eng_texts)\n","    snd_texts = list(snd_texts)\n","    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, snd_texts))\n","    dataset = dataset.batch(BATCH_SIZE)\n","    dataset = dataset.map(preprocess_batch, num_parallel_calls=tf.data.AUTOTUNE)\n","    return dataset.shuffle(2048).prefetch(16).cache()\n","\n","\n","train_ds = make_dataset(train_pairs)\n","val_ds = make_dataset(val_pairs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rhiDWnOuzGN_"},"outputs":[],"source":["# Encoder\n","encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n","\n","x = keras_nlp.layers.TokenAndPositionEmbedding(\n","    vocabulary_size=ENG_VOCAB_SIZE,\n","    sequence_length=MAX_SEQUENCE_LENGTH,\n","    embedding_dim=EMBED_DIM,\n","    mask_zero=True,\n",")(encoder_inputs)\n","\n","encoder_outputs = keras_nlp.layers.TransformerEncoder(\n","    intermediate_dim=INTERMEDIATE_DIM, num_heads=NUM_HEADS\n",")(inputs=x)\n","encoder = keras.Model(encoder_inputs, encoder_outputs)\n","\n","\n","# Decoder\n","decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n","encoded_seq_inputs = keras.Input(shape=(None, EMBED_DIM), name=\"decoder_state_inputs\")\n","\n","x = keras_nlp.layers.TokenAndPositionEmbedding(\n","    vocabulary_size=SND_VOCAB_SIZE,\n","    sequence_length=MAX_SEQUENCE_LENGTH,\n","    embedding_dim=EMBED_DIM,\n","    mask_zero=True,\n",")(decoder_inputs)\n","\n","x = keras_nlp.layers.TransformerDecoder(\n","    intermediate_dim=INTERMEDIATE_DIM, num_heads=NUM_HEADS\n",")(decoder_sequence=x, encoder_sequence=encoded_seq_inputs)\n","x = keras.layers.Dropout(0.5)(x)\n","decoder_outputs = keras.layers.Dense(SND_VOCAB_SIZE, activation=\"softmax\")(x)\n","decoder = keras.Model(\n","    [\n","        decoder_inputs,\n","        encoded_seq_inputs,\n","    ],\n","    decoder_outputs,\n",")\n","decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n","\n","transformer = keras.Model(\n","    [encoder_inputs, decoder_inputs],\n","    decoder_outputs,\n","    name=\"transformer\",\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1128865,"status":"ok","timestamp":1670430129712,"user":{"displayName":"Ramsha Ghulam Mustafa","userId":"01894469828690764953"},"user_tz":-300},"id":"9Hs1U3VXzZL4","outputId":"935c30c7-75a9-419c-9da5-9bd6702d5214"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"transformer\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," encoder_inputs (InputLayer)    [(None, None)]       0           []                               \n","                                                                                                  \n"," token_and_position_embedding (  (None, None, 256)   26856960    ['encoder_inputs[0][0]']         \n"," TokenAndPositionEmbedding)                                                                       \n","                                                                                                  \n"," decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n","                                                                                                  \n"," transformer_encoder (Transform  (None, None, 256)   1315072     ['token_and_position_embedding[0]\n"," erEncoder)                                                      [0]']                            \n","                                                                                                  \n"," model_1 (Functional)           (None, None, 104890  56311738    ['decoder_inputs[0][0]',         \n","                                )                                 'transformer_encoder[0][0]']    \n","                                                                                                  \n","==================================================================================================\n","Total params: 84,483,770\n","Trainable params: 84,483,770\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Epoch 1/5\n","574/574 [==============================] - 219s 371ms/step - loss: 2.0961 - accuracy: 0.3206 - val_loss: 1.6321 - val_accuracy: 0.4339\n","Epoch 2/5\n","574/574 [==============================] - 216s 376ms/step - loss: 1.4955 - accuracy: 0.4943 - val_loss: 1.2273 - val_accuracy: 0.5670\n","Epoch 3/5\n","574/574 [==============================] - 215s 376ms/step - loss: 1.1693 - accuracy: 0.5967 - val_loss: 0.9743 - val_accuracy: 0.6442\n","Epoch 4/5\n","574/574 [==============================] - 215s 375ms/step - loss: 0.9762 - accuracy: 0.6539 - val_loss: 0.8606 - val_accuracy: 0.6763\n","Epoch 5/5\n","574/574 [==============================] - 215s 375ms/step - loss: 0.8607 - accuracy: 0.6890 - val_loss: 0.8013 - val_accuracy: 0.6955\n"]}],"source":["transformer.summary()\n","transformer.compile(\n","    \"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",")\n","hist = transformer.fit(train_ds, epochs=5, validation_data=val_ds)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1474,"status":"ok","timestamp":1670430135722,"user":{"displayName":"Ramsha Ghulam Mustafa","userId":"01894469828690764953"},"user_tz":-300},"id":"0eLl6U2h2AiM","outputId":"16891924-fc62-4de4-b7bf-42508b785e62"},"outputs":[{"name":"stdout","output_type":"stream","text":["Saved model to disk\n"]}],"source":["# serialize model to JSON\n","model_json = transformer.to_json()\n","with open(\"/content/drive/MyDrive/model_KerasNLP.json\", \"w\") as json_file:\n","  json_file.write(model_json)\n","# serialize weights to HDF5\n","transformer.save_weights(\"/content/drive/MyDrive/model_KerasNLP.h5\")\n","print(\"Saved model to disk\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10758,"status":"ok","timestamp":1670490425205,"user":{"displayName":"Ramsha Ghulam Mustafa","userId":"01894469828690764953"},"user_tz":-300},"id":"SOB1XBoK2ki3","outputId":"54263360-aab1-497d-8eb3-437007d619b4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loaded model from disk\n"]}],"source":["# load json and create model\n","json_file = open('/content/drive/MyDrive/model_KerasNLP.json', 'r')\n","loaded_model_json = json_file.read()\n","json_file.close()\n","model = model_from_json(loaded_model_json, custom_objects={'TokenAndPositionEmbedding': keras_nlp.layers.TokenAndPositionEmbedding,\n","                                                                  'TransformerEncoder': keras_nlp.layers.TransformerEncoder,\n","                                                                  'TransformerDecoder': keras_nlp.layers.TransformerDecoder})\n","# load weights into new model\n","model.load_weights(\"/content/drive/MyDrive/model_KerasNLP.h5\")\n","print(\"Loaded model from disk\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RnUlCqbJ30bY"},"outputs":[],"source":["def decode_sequences(input_sentences):\n","  batch_size = tf.shape(input_sentences)[0]\n","\n","  # Tokenize the encoder input.\n","  encoder_input_tokens = eng_tokenizer(input_sentences).to_tensor(\n","    shape=(None, MAX_SEQUENCE_LENGTH)\n","  )\n","\n","  # Define a function that outputs the next token's probability given the\n","  # input sequence.\n","  def token_probability_fn(decoder_input_tokens):\n","    return model([encoder_input_tokens, decoder_input_tokens])[:, -1, :]\n","\n","  # Set the prompt to the \"[START]\" token.\n","  prompt = tf.fill((batch_size, 1), snd_tokenizer.token_to_id(\"[START]\"))\n","\n","  generated_tokens = keras_nlp.utils.greedy_search(\n","    token_probability_fn,\n","    prompt,\n","    max_length=20,\n","    end_token_id=snd_tokenizer.token_to_id(\"[END]\"),\n","  )\n","  generated_sentences = snd_tokenizer.detokenize(generated_tokens)\n","  return generated_sentences\n","\n","\n","translated = decode_sequences(tf.constant(['this is dog']))\n","translated = translated.numpy()[0].decode(\"utf-8\")\n","translated = (\n","    translated.replace(\"[PAD]\", \"\")\n","    .replace(\"[START]\", \"\")\n","    .replace(\"[END]\", \"\")\n","    .strip()\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":487,"status":"ok","timestamp":1670487221282,"user":{"displayName":"Ramsha Ghulam Mustafa","userId":"01894469828690764953"},"user_tz":-300},"id":"2RoweDhPGSkG","outputId":"a8134c26-d6f0-4654-d27d-ad3f388807f0"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/English-to-Sindhi Translation\n"]}],"source":["cd /content/drive/MyDrive/English-to-Sindhi Translation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1093,"status":"ok","timestamp":1670490436887,"user":{"displayName":"Ramsha Ghulam Mustafa","userId":"01894469828690764953"},"user_tz":-300},"id":"upWq8_c3C2n2","outputId":"4aa01317-e868-46ba-9074-c8c4c08c1b7a"},"outputs":[{"name":"stdout","output_type":"stream","text":["هي هوس اهي\n"]}],"source":["print(translated)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5200,"status":"ok","timestamp":1670490443131,"user":{"displayName":"Ramsha Ghulam Mustafa","userId":"01894469828690764953"},"user_tz":-300},"id":"dgDYZShn6bWv","outputId":"c7713ddb-4e5d-42d1-8e29-9df8e4981465"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting flask-ngrok\n","  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from flask-ngrok) (2.23.0)\n","Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.8/dist-packages (from flask-ngrok) (1.1.4)\n","Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.8/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n","Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.8/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n","Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.8/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n","Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.8/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask-ngrok) (2.0.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->flask-ngrok) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->flask-ngrok) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->flask-ngrok) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->flask-ngrok) (3.0.4)\n","Installing collected packages: flask-ngrok\n","Successfully installed flask-ngrok-0.0.25\n"]}],"source":["!pip install flask-ngrok"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":57583,"status":"ok","timestamp":1670496064175,"user":{"displayName":"Ramsha Ghulam Mustafa","userId":"01894469828690764953"},"user_tz":-300},"id":"CI3wXZ7Y_o7W","outputId":"8f4e9a73-8681-4e13-aa15-9a2009140174"},"outputs":[{"output_type":"stream","name":"stdout","text":["Enter your authtoken, which can be copied from https://dashboard.ngrok.com/auth\n","··········\n"," * ngrok tunnel available, access with `ssh root@4.tcp.ngrok.io -p15448`\n"]}],"source":["import getpass\n","\n","from pyngrok import ngrok, conf\n","\n","print(\"Enter your authtoken, which can be copied from https://dashboard.ngrok.com/auth\")\n","conf.get_default().auth_token = getpass.getpass()\n","\n","# Open a TCP ngrok tunnel to the SSH server\n","connection_string = ngrok.connect(22, \"tcp\").public_url\n","\n","ssh_url, port = connection_string.strip(\"tcp://\").split(\":\")\n","print(f\" * ngrok tunnel available, access with `ssh root@{ssh_url} -p{port}`\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iA42iPNvBefK"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"executionInfo":{"elapsed":41,"status":"error","timestamp":1670557077854,"user":{"displayName":"Ramsha Ghulam Mustafa","userId":"01894469828690764953"},"user_tz":-300},"id":"1QsOl3Zm_4dF","outputId":"1fb0cfb9-7538-47cd-b9c9-465d7c1e2195"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-d7e4c5da94e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mflask_ngrok\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrun_with_ngrok\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflask\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFlask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrender_template\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwtforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mForm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTextAreaField\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'flask_ngrok'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["from flask_ngrok import run_with_ngrok\n","from flask import Flask, render_template, request\n","from wtforms import Form, TextAreaField, validators\n","import pickle\n","import os\n","import numpy as np\n","import keras_nlp\n","import numpy as np\n","import pandas as pd\n","import pathlib\n","import random\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import keras\n","from keras.models import  model_from_json\n","import getpass\n","from pyngrok import ngrok, conf\n","from tensorflow_text.tools.wordpiece_vocab import bert_vocab_from_dataset as bert_vocab\n","\n","print(\"Enter your authtoken, which can be copied from https://dashboard.ngrok.com/auth\")\n","conf.get_default().auth_token = getpass.getpass()\n","\n","# Open a TCP ngrok tunnel to the SSH server\n","connection_string = ngrok.connect(22, \"tcp\").public_url\n","\n","ssh_url, port = connection_string.strip(\"tcp://\").split(\":\")\n","print(f\" * ngrok tunnel available, access with `ssh root@{ssh_url} -p{port}`\")\n","\n","app = Flask(__name__)\n","run_with_ngrok(app)\n","app.config['SECRET_KEY'] = \"abcmsdihgiosjawfjeioghaegnklaebn\"\n","\n","\n","\n","@app.route('/')\n","def index():\n","    return render_template('input_form.html')\n","\n","def decode_sequences(input_sentences):\n","  batch_size = tf.shape(input_sentences)[0]\n","\n","  # Tokenize the encoder input.\n","  encoder_input_tokens = eng_tokenizer(input_sentences).to_tensor(\n","    shape=(None, MAX_SEQUENCE_LENGTH)\n","  )\n","\n","  # Define a function that outputs the next token's probability given the\n","  # input sequence.\n","  def token_probability_fn(decoder_input_tokens):\n","    return model([encoder_input_tokens, decoder_input_tokens])[:, -1, :]\n","\n","  # Set the prompt to the \"[START]\" token.\n","  prompt = tf.fill((batch_size, 1), snd_tokenizer.token_to_id(\"[START]\"))\n","\n","  generated_tokens = keras_nlp.utils.greedy_search(\n","    token_probability_fn,\n","    prompt,\n","    max_length=20,\n","    end_token_id=snd_tokenizer.token_to_id(\"[END]\"),\n","  )\n","  generated_sentences = snd_tokenizer.detokenize(generated_tokens)\n","  return generated_sentences\n","\n","\n","\n","@app.route('/results', methods=['POST'])\n","def transate():\n","    text = request.form['text']\n","\n","    translated = decode_sequences(tf.constant([text]))\n","    translated = translated.numpy()[0].decode(\"utf-8\")\n","    translated = (\n","        translated.replace(\"[PAD]\", \"\")\n","        .replace(\"[START]\", \"\")\n","        .replace(\"[END]\", \"\")\n","        .strip()\n","    )\n","    \n","    return render_template('results.html', predicted_text=translated)\n","\n","\n","app.run()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5394,"status":"ok","timestamp":1670490614102,"user":{"displayName":"Ramsha Ghulam Mustafa","userId":"01894469828690764953"},"user_tz":-300},"id":"vGDlkA2CFys4","outputId":"b7684f00-b3f9-498d-a0d6-8f63cf4f5018"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting wtforms\n","  Downloading WTForms-3.0.1-py3-none-any.whl (136 kB)\n","\u001b[K     |████████████████████████████████| 136 kB 10.2 MB/s \n","\u001b[?25hRequirement already satisfied: MarkupSafe in /usr/local/lib/python3.8/dist-packages (from wtforms) (2.0.1)\n","Installing collected packages: wtforms\n","Successfully installed wtforms-3.0.1\n"]}],"source":["!pip install wtforms"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1670487233083,"user":{"displayName":"Ramsha Ghulam Mustafa","userId":"01894469828690764953"},"user_tz":-300},"id":"xv6ZKA9Jfg1e","outputId":"076ceefd-848f-4a66-95f2-db982a9ae862"},"outputs":[{"name":"stdout","output_type":"stream","text":["/bin/bash: ngrok: command not found\n"]}],"source":["!ngrok config add-authtoken 2Iar0FThbid00EdrNZaLJRCeYU5_4uktgMyy7EESP26TDnBTn"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10225,"status":"ok","timestamp":1670487243298,"user":{"displayName":"Ramsha Ghulam Mustafa","userId":"01894469828690764953"},"user_tz":-300},"id":"tolAyiCN8k5E","outputId":"9a45358e-5e71-4dba-a0f5-db0bfd974d9f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting flask==0.12.2\n","  Downloading Flask-0.12.2-py2.py3-none-any.whl (83 kB)\n","\u001b[K     |████████████████████████████████| 83 kB 1.2 MB/s \n","\u001b[?25hRequirement already satisfied: Werkzeug>=0.7 in /usr/local/lib/python3.8/dist-packages (from flask==0.12.2) (1.0.1)\n","Requirement already satisfied: itsdangerous>=0.21 in /usr/local/lib/python3.8/dist-packages (from flask==0.12.2) (1.1.0)\n","Requirement already satisfied: Jinja2>=2.4 in /usr/local/lib/python3.8/dist-packages (from flask==0.12.2) (2.11.3)\n","Requirement already satisfied: click>=2.0 in /usr/local/lib/python3.8/dist-packages (from flask==0.12.2) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from Jinja2>=2.4->flask==0.12.2) (2.0.1)\n","Installing collected packages: flask\n","  Attempting uninstall: flask\n","    Found existing installation: Flask 1.1.4\n","    Uninstalling Flask-1.1.4:\n","      Successfully uninstalled Flask-1.1.4\n","Successfully installed flask-0.12.2\n"]}],"source":["!pip install flask==0.12.2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":526},"executionInfo":{"elapsed":946,"status":"error","timestamp":1670491691097,"user":{"displayName":"Ramsha Ghulam Mustafa","userId":"01894469828690764953"},"user_tz":-300},"id":"9SgIyIuY6-Vu","outputId":"c61f8977-3c27-4e27-b27a-80757c15dce1"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:pyngrok.process.ngrok:t=2022-12-08T09:28:10+0000 lvl=warn msg=\"failed to start tunnel\" pg=/api/tunnels id=094d58f35797210f err=\"Your account may not run more than 3 tunnels over a single ngrok agent session.\\nThe tunnels already running on this session are:\\ntn_2Icr6zOibISrPl6mZtata9PGyLk, tn_2IcrPpeZhbkqCv3wbQbcBLDN4fS, tn_2Icr71gMEGLfmWBomjY68zfqOkh\\n\\r\\n\\r\\nERR_NGROK_324\\r\\n\"\n"]},{"ename":"PyngrokNgrokHTTPError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(url, method, data, params, timeout)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m         \u001b[0mresponse_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    641\u001b[0m                 'http', request, response, code, msg, hdrs)\n","\u001b[0;32m/usr/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mHTTPError\u001b[0m: HTTP Error 502: Bad Gateway","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mPyngrokNgrokHTTPError\u001b[0m                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-37-6053cde4758f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Open a ngrok tunnel to the HTTP server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mpublic_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mngrok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublic_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" * ngrok tunnel \\\"{}\\\" -> \\\"http://127.0.0.1:{}\\\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpublic_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(addr, proto, name, pyngrok_config, **options)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating tunnel with options: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     tunnel = NgrokTunnel(api_request(\"{}/api/tunnels\".format(api_url), method=\"POST\", data=options,\n\u001b[0m\u001b[1;32m    272\u001b[0m                                      timeout=pyngrok_config.request_timeout),\n\u001b[1;32m    273\u001b[0m                          pyngrok_config, api_url)\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(url, method, data, params, timeout)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Response {}: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         raise PyngrokNgrokHTTPError(\"ngrok client exception, API returned {}: {}\".format(status_code, response_data),\n\u001b[0m\u001b[1;32m    478\u001b[0m                                     \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m                                     status_code, e.msg, e.hdrs, response_data)\n","\u001b[0;31mPyngrokNgrokHTTPError\u001b[0m: ngrok client exception, API returned 502: {\"error_code\":103,\"status_code\":502,\"msg\":\"failed to start tunnel\",\"details\":{\"err\":\"Your account may not run more than 3 tunnels over a single ngrok agent session.\\nThe tunnels already running on this session are:\\ntn_2Icr6zOibISrPl6mZtata9PGyLk, tn_2IcrPpeZhbkqCv3wbQbcBLDN4fS, tn_2Icr71gMEGLfmWBomjY68zfqOkh\\n\\r\\n\\r\\nERR_NGROK_324\\r\\n\"}}\n"]}],"source":["from flask_ngrok import run_with_ngrok\n","from flask import Flask, render_template, request\n","from wtforms import Form, TextAreaField, validators\n","import numpy as np\n","import keras_nlp\n","import numpy as np\n","import pandas as pd\n","import pathlib\n","import random\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import keras\n","from keras.models import  model_from_json\n","from tensorflow_text.tools.wordpiece_vocab import bert_vocab_from_dataset as bert_vocab\n","import os\n","import threading\n","from flask import Flask\n","from pyngrok import ngrok\n","\n","os.environ[\"FLASK_ENV\"] = \"development\"\n","\n","app = Flask(__name__)\n","port = 5000\n","\n","# Open a ngrok tunnel to the HTTP server\n","public_url = ngrok.connect(port).public_url\n","print(\" * ngrok tunnel \\\"{}\\\" -> \\\"http://127.0.0.1:{}\\\"\".format(public_url, port))\n","\n","# Update any base URLs to use the public ngrok URL\n","app.config[\"BASE_URL\"] = public_url\n","\n","@app.route('/')\n","def index():\n","    return render_template('input_form.html')\n","\n","def decode_sequences(input_sentences):\n","  batch_size = tf.shape(input_sentences)[0]\n","\n","  # Tokenize the encoder input.\n","  encoder_input_tokens = eng_tokenizer(input_sentences).to_tensor(\n","    shape=(None, MAX_SEQUENCE_LENGTH)\n","  )\n","\n","  # Define a function that outputs the next token's probability given the\n","  # input sequence.\n","  def token_probability_fn(decoder_input_tokens):\n","    return model([encoder_input_tokens, decoder_input_tokens])[:, -1, :]\n","\n","  # Set the prompt to the \"[START]\" token.\n","  prompt = tf.fill((batch_size, 1), snd_tokenizer.token_to_id(\"[START]\"))\n","\n","  generated_tokens = keras_nlp.utils.greedy_search(\n","    token_probability_fn,\n","    prompt,\n","    max_length=20,\n","    end_token_id=snd_tokenizer.token_to_id(\"[END]\"),\n","  )\n","  generated_sentences = snd_tokenizer.detokenize(generated_tokens)\n","  return generated_sentences\n","\n","\n","\n","@app.route('/results', methods=['POST'])\n","def transate():\n","    text = request.form['text']\n","\n","    translated = decode_sequences(tf.constant([text]))\n","    translated = translated.numpy()[0].decode(\"utf-8\")\n","    translated = (\n","        translated.replace(\"[PAD]\", \"\")\n","        .replace(\"[START]\", \"\")\n","        .replace(\"[END]\", \"\")\n","        .strip()\n","    )\n","    \n","    return render_template('results.html', predicted_text=translated)\n","\n","\n","\n","\n","# Start the Flask server in a new thread\n","threading.Thread(target=app.run, kwargs={\"use_reloader\": False}).start()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4043,"status":"ok","timestamp":1670495975445,"user":{"displayName":"Ramsha Ghulam Mustafa","userId":"01894469828690764953"},"user_tz":-300},"id":"9GPMqswNDP0Z","outputId":"54b539c4-2a3e-4f43-b1e4-48fba22a3f40"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pyngrok in /usr/local/lib/python3.8/dist-packages (5.2.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from pyngrok) (6.0)\n"]}],"source":["!pip install pyngrok\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":48273,"status":"ok","timestamp":1670488218215,"user":{"displayName":"Ramsha Ghulam Mustafa","userId":"01894469828690764953"},"user_tz":-300},"id":"PH1DzLnmChL-","outputId":"b9f08bc9-ac98-47af-c67b-3d5a23e8bbc4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting colabcode\n","  Downloading colabcode-0.3.0-py3-none-any.whl (5.0 kB)\n","Collecting nest-asyncio==1.4.3\n","  Downloading nest_asyncio-1.4.3-py3-none-any.whl (5.3 kB)\n","Collecting jupyterlab==3.0.7\n","  Downloading jupyterlab-3.0.7-py3-none-any.whl (8.3 MB)\n","\u001b[K     |████████████████████████████████| 8.3 MB 5.4 MB/s \n","\u001b[?25hRequirement already satisfied: pyngrok>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from colabcode) (5.2.1)\n","Collecting uvicorn==0.13.1\n","  Downloading uvicorn-0.13.1-py3-none-any.whl (45 kB)\n","\u001b[K     |████████████████████████████████| 45 kB 3.6 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from jupyterlab==3.0.7->colabcode) (21.3)\n","Collecting nbclassic~=0.2\n","  Downloading nbclassic-0.4.8-py3-none-any.whl (9.8 MB)\n","\u001b[K     |████████████████████████████████| 9.8 MB 38.2 MB/s \n","\u001b[?25hCollecting jupyter-server~=1.2\n","  Downloading jupyter_server-1.23.3-py3-none-any.whl (346 kB)\n","\u001b[K     |████████████████████████████████| 346 kB 48.4 MB/s \n","\u001b[?25hRequirement already satisfied: jupyter-core in /usr/local/lib/python3.8/dist-packages (from jupyterlab==3.0.7->colabcode) (5.1.0)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from jupyterlab==3.0.7->colabcode) (7.9.0)\n","Collecting tornado>=6.1.0\n","  Downloading tornado-6.2-cp37-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (423 kB)\n","\u001b[K     |████████████████████████████████| 423 kB 54.7 MB/s \n","\u001b[?25hCollecting jupyterlab-server~=2.0\n","  Downloading jupyterlab_server-2.16.3-py3-none-any.whl (54 kB)\n","\u001b[K     |████████████████████████████████| 54 kB 2.6 MB/s \n","\u001b[?25hRequirement already satisfied: jinja2>=2.10 in /usr/local/lib/python3.8/dist-packages (from jupyterlab==3.0.7->colabcode) (2.11.3)\n","Collecting h11>=0.8\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[K     |████████████████████████████████| 58 kB 5.5 MB/s \n","\u001b[?25hRequirement already satisfied: click==7.* in /usr/local/lib/python3.8/dist-packages (from uvicorn==0.13.1->colabcode) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2>=2.10->jupyterlab==3.0.7->colabcode) (2.0.1)\n","Collecting websocket-client\n","  Downloading websocket_client-1.4.2-py3-none-any.whl (55 kB)\n","\u001b[K     |████████████████████████████████| 55 kB 3.8 MB/s \n","\u001b[?25hCollecting nbconvert>=6.4.4\n","  Downloading nbconvert-7.2.6-py3-none-any.whl (273 kB)\n","\u001b[K     |████████████████████████████████| 273 kB 62.8 MB/s \n","\u001b[?25hRequirement already satisfied: Send2Trash in /usr/local/lib/python3.8/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (1.8.0)\n","Requirement already satisfied: prometheus-client in /usr/local/lib/python3.8/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.15.0)\n","Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.8/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (5.6.0)\n","Requirement already satisfied: nbformat>=5.2.0 in /usr/local/lib/python3.8/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (5.7.0)\n","Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.8/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (23.2.1)\n","Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.8/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (6.1.12)\n","Collecting anyio<4,>=3.1.0\n","  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n","\u001b[K     |████████████████████████████████| 80 kB 8.4 MB/s \n","\u001b[?25hCollecting argon2-cffi\n","  Downloading argon2_cffi-21.3.0-py3-none-any.whl (14 kB)\n","Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.8/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.13.3)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.8/dist-packages (from anyio<4,>=3.1.0->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (2.10)\n","Collecting sniffio>=1.1\n","  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from jupyter-client>=6.1.12->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (2.8.2)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.8/dist-packages (from jupyter-core->jupyterlab==3.0.7->colabcode) (2.5.4)\n","Collecting jinja2>=2.10\n","  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n","\u001b[K     |████████████████████████████████| 133 kB 62.8 MB/s \n","\u001b[?25hRequirement already satisfied: babel in /usr/local/lib/python3.8/dist-packages (from jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (2.11.0)\n","Collecting json5\n","  Downloading json5-0.9.10-py2.py3-none-any.whl (19 kB)\n","Requirement already satisfied: jsonschema>=3.0.1 in /usr/local/lib/python3.8/dist-packages (from jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (4.3.3)\n","Requirement already satisfied: importlib-metadata>=4.8.3 in /usr/local/lib/python3.8/dist-packages (from jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (4.13.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (2.23.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.8.3->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (3.11.0)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (22.1.0)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (5.10.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (0.19.2)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.8/dist-packages (from nbclassic~=0.2->jupyterlab==3.0.7->colabcode) (0.2.0)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.8/dist-packages (from nbclassic~=0.2->jupyterlab==3.0.7->colabcode) (5.3.4)\n","Collecting nbclassic~=0.2\n","  Downloading nbclassic-0.4.7-py3-none-any.whl (9.8 MB)\n","\u001b[K     |████████████████████████████████| 9.8 MB 39.0 MB/s \n","\u001b[?25h  Downloading nbclassic-0.4.6-py3-none-any.whl (9.8 MB)\n","\u001b[K     |████████████████████████████████| 9.8 MB 47.3 MB/s \n","\u001b[?25h  Downloading nbclassic-0.4.5-py3-none-any.whl (9.8 MB)\n","\u001b[K     |████████████████████████████████| 9.8 MB 41.9 MB/s \n","\u001b[?25h  Downloading nbclassic-0.4.4-py3-none-any.whl (9.8 MB)\n","\u001b[K     |████████████████████████████████| 9.8 MB 35.4 MB/s \n","\u001b[?25h  Downloading nbclassic-0.4.3-py3-none-any.whl (9.7 MB)\n","\u001b[K     |████████████████████████████████| 9.7 MB 23.2 MB/s \n","\u001b[?25h  Downloading nbclassic-0.4.2-py3-none-any.whl (9.7 MB)\n","\u001b[K     |████████████████████████████████| 9.7 MB 44.2 MB/s \n","\u001b[?25h  Downloading nbclassic-0.4.0-py3-none-any.whl (9.7 MB)\n","\u001b[K     |████████████████████████████████| 9.7 MB 45.1 MB/s \n","\u001b[?25h  Downloading nbclassic-0.3.7-py3-none-any.whl (13 kB)\n","Collecting notebook-shim>=0.1.0\n","  Downloading notebook_shim-0.2.2-py3-none-any.whl (13 kB)\n","Requirement already satisfied: notebook<7 in /usr/local/lib/python3.8/dist-packages (from nbclassic~=0.2->jupyterlab==3.0.7->colabcode) (5.7.16)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.8/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.7.1)\n","Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (2.6.1)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.8/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (5.0.1)\n","Collecting mistune<3,>=2.0.3\n","  Downloading mistune-2.0.4-py2.py3-none-any.whl (24 kB)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (4.6.3)\n","Collecting nbclient>=0.5.0\n","  Downloading nbclient-0.7.2-py3-none-any.whl (71 kB)\n","\u001b[K     |████████████████████████████████| 71 kB 279 kB/s \n","\u001b[?25hRequirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (1.5.0)\n","Collecting jupyterlab-pygments\n","  Downloading jupyterlab_pygments-0.2.2-py2.py3-none-any.whl (21 kB)\n","Collecting tinycss2\n","  Downloading tinycss2-1.2.1-py3-none-any.whl (21 kB)\n","Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.8/dist-packages (from nbformat>=5.2.0->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (2.16.2)\n","Collecting notebook<7\n","  Downloading notebook-6.5.2-py3-none-any.whl (439 kB)\n","\u001b[K     |████████████████████████████████| 439 kB 43.9 MB/s \n","\u001b[?25h  Downloading notebook-6.5.1-py3-none-any.whl (439 kB)\n","\u001b[K     |████████████████████████████████| 439 kB 51.3 MB/s \n","\u001b[?25h  Downloading notebook-6.4.12-py3-none-any.whl (9.9 MB)\n","\u001b[K     |████████████████████████████████| 9.9 MB 49.4 MB/s \n","\u001b[?25h  Downloading notebook-6.4.11-py3-none-any.whl (9.9 MB)\n","\u001b[K     |████████████████████████████████| 9.9 MB 38.4 MB/s \n","\u001b[?25h  Downloading notebook-6.4.10-py3-none-any.whl (9.9 MB)\n","\u001b[K     |████████████████████████████████| 9.9 MB 43.2 MB/s \n","\u001b[?25h  Downloading notebook-6.4.9-py3-none-any.whl (9.9 MB)\n","\u001b[K     |████████████████████████████████| 9.9 MB 41.7 MB/s \n","\u001b[?25h  Downloading notebook-6.4.8-py3-none-any.whl (9.9 MB)\n","\u001b[K     |████████████████████████████████| 9.9 MB 37.8 MB/s \n","\u001b[?25h  Downloading notebook-6.4.7-py3-none-any.whl (9.9 MB)\n","\u001b[K     |████████████████████████████████| 9.9 MB 35.8 MB/s \n","\u001b[?25h  Downloading notebook-6.4.6-py3-none-any.whl (9.9 MB)\n","\u001b[K     |████████████████████████████████| 9.9 MB 36.4 MB/s \n","\u001b[?25h  Downloading notebook-6.4.5-py3-none-any.whl (9.9 MB)\n","\u001b[K     |████████████████████████████████| 9.9 MB 36.4 MB/s \n","\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from pyngrok>=5.0.0->colabcode) (6.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->jupyter-client>=6.1.12->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (1.15.0)\n","Requirement already satisfied: ptyprocess in /usr/local/lib/python3.8/dist-packages (from terminado>=0.8.3->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.7.0)\n","Collecting argon2-cffi-bindings\n","  Downloading argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (86 kB)\n","\u001b[K     |████████████████████████████████| 86 kB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (1.15.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (2.21)\n","Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.8/dist-packages (from babel->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (2022.6)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.8/dist-packages (from bleach->nbconvert>=6.4.4->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.5.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (0.7.5)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (57.4.0)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (4.8.0)\n","Collecting jedi>=0.10\n","  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 48.1 MB/s \n","\u001b[?25hRequirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (0.2.0)\n","Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (2.0.10)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython->jupyterlab==3.0.7->colabcode) (0.8.3)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->jupyterlab==3.0.7->colabcode) (0.2.5)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->jupyterlab==3.0.7->colabcode) (3.0.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (2022.9.24)\n","Installing collected packages: tornado, tinycss2, sniffio, nbclient, mistune, jupyterlab-pygments, jinja2, jedi, argon2-cffi-bindings, websocket-client, nbconvert, argon2-cffi, anyio, jupyter-server, notebook-shim, notebook, json5, nbclassic, jupyterlab-server, h11, uvicorn, nest-asyncio, jupyterlab, colabcode\n","  Attempting uninstall: tornado\n","    Found existing installation: tornado 6.0.4\n","    Uninstalling tornado-6.0.4:\n","      Successfully uninstalled tornado-6.0.4\n","  Attempting uninstall: mistune\n","    Found existing installation: mistune 0.8.4\n","    Uninstalling mistune-0.8.4:\n","      Successfully uninstalled mistune-0.8.4\n","  Attempting uninstall: jinja2\n","    Found existing installation: Jinja2 2.11.3\n","    Uninstalling Jinja2-2.11.3:\n","      Successfully uninstalled Jinja2-2.11.3\n","  Attempting uninstall: nbconvert\n","    Found existing installation: nbconvert 5.6.1\n","    Uninstalling nbconvert-5.6.1:\n","      Successfully uninstalled nbconvert-5.6.1\n","  Attempting uninstall: notebook\n","    Found existing installation: notebook 5.7.16\n","    Uninstalling notebook-5.7.16:\n","      Successfully uninstalled notebook-5.7.16\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires notebook~=5.7.16, but you have notebook 6.4.5 which is incompatible.\n","google-colab 1.0.0 requires tornado~=6.0.4, but you have tornado 6.2 which is incompatible.\u001b[0m\n","Successfully installed anyio-3.6.2 argon2-cffi-21.3.0 argon2-cffi-bindings-21.2.0 colabcode-0.3.0 h11-0.14.0 jedi-0.18.2 jinja2-3.1.2 json5-0.9.10 jupyter-server-1.23.3 jupyterlab-3.0.7 jupyterlab-pygments-0.2.2 jupyterlab-server-2.16.3 mistune-2.0.4 nbclassic-0.3.7 nbclient-0.7.2 nbconvert-7.2.6 nest-asyncio-1.4.3 notebook-6.4.5 notebook-shim-0.2.2 sniffio-1.3.0 tinycss2-1.2.1 tornado-6.2 uvicorn-0.13.1 websocket-client-1.4.2\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["jinja2","tornado"]}}},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting fastapi\n","  Downloading fastapi-0.88.0-py3-none-any.whl (55 kB)\n","\u001b[K     |████████████████████████████████| 55 kB 2.2 MB/s \n","\u001b[?25hRequirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in /usr/local/lib/python3.8/dist-packages (from fastapi) (1.10.2)\n","Collecting starlette==0.22.0\n","  Downloading starlette-0.22.0-py3-none-any.whl (64 kB)\n","\u001b[K     |████████████████████████████████| 64 kB 2.7 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.8/dist-packages (from starlette==0.22.0->fastapi) (4.4.0)\n","Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from starlette==0.22.0->fastapi) (3.6.2)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.8/dist-packages (from anyio<5,>=3.4.0->starlette==0.22.0->fastapi) (2.10)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.8/dist-packages (from anyio<5,>=3.4.0->starlette==0.22.0->fastapi) (1.3.0)\n","Installing collected packages: starlette, fastapi\n","Successfully installed fastapi-0.88.0 starlette-0.22.0\n"]}],"source":["!pip install colabcode\n","!pip install fastapi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e9UaJLrq2nWC"},"outputs":[],"source":["from colabcode import ColabCode\n","from fastapi import FastAPI"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8szirCqk21jw"},"outputs":[],"source":["cc = ColabCode(port=12000, code=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hIrvAN1C2_rJ"},"outputs":[],"source":["app = FastAPI()\n","\n","@app.get('/')\n","async def read_root():\n","  return {'Hello' : 'World'}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15916,"status":"ok","timestamp":1670488479494,"user":{"displayName":"Ramsha Ghulam Mustafa","userId":"01894469828690764953"},"user_tz":-300},"id":"EOoJKk4W3U1_","outputId":"fe09ed64-cbf8-46b1-dd7e-b8d88bcefe0e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Public URL: NgrokTunnel: \"https://456d-34-73-2-153.ngrok.io\" -> \"http://localhost:12000\"\n"]},{"name":"stderr","output_type":"stream","text":["INFO:     Started server process [73]\n","INFO:uvicorn.error:Started server process [73]\n","INFO:     Waiting for application startup.\n","INFO:uvicorn.error:Waiting for application startup.\n","INFO:     Application startup complete.\n","INFO:uvicorn.error:Application startup complete.\n","INFO:     Uvicorn running on http://127.0.0.1:12000 (Press CTRL+C to quit)\n","INFO:uvicorn.error:Uvicorn running on http://127.0.0.1:12000 (Press CTRL+C to quit)\n"]},{"name":"stdout","output_type":"stream","text":["INFO:     121.52.154.73:0 - \"GET / HTTP/1.1\" 200 OK\n","INFO:     121.52.154.73:0 - \"GET /favicon.ico HTTP/1.1\" 404 Not Found\n"]},{"name":"stderr","output_type":"stream","text":["INFO:     Shutting down\n","INFO:uvicorn.error:Shutting down\n","INFO:     Waiting for application shutdown.\n","INFO:uvicorn.error:Waiting for application shutdown.\n","INFO:     Application shutdown complete.\n","INFO:uvicorn.error:Application shutdown complete.\n","INFO:     Finished server process [73]\n","INFO:uvicorn.error:Finished server process [73]\n"]}],"source":["cc.run_app(app=app)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":450},"executionInfo":{"elapsed":581,"status":"error","timestamp":1670496099376,"user":{"displayName":"Ramsha Ghulam Mustafa","userId":"01894469828690764953"},"user_tz":-300},"id":"76e6loJD3X_1","outputId":"3bc74c7b-9738-4b98-d15d-91efd11f1c8f"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:pyngrok.process.ngrok:t=2022-12-08T10:41:39+0000 lvl=warn msg=\"failed to start tunnel\" pg=/api/tunnels id=c2ec73163cbd2fc5 err=EOF\n"]},{"output_type":"error","ename":"PyngrokNgrokHTTPError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(url, method, data, params, timeout)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m         \u001b[0mresponse_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    641\u001b[0m                 'http', request, response, code, msg, hdrs)\n","\u001b[0;32m/usr/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mHTTPError\u001b[0m: HTTP Error 502: Bad Gateway","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mPyngrokNgrokHTTPError\u001b[0m                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-49-ba3859f453ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Open a ngrok tunnel to the HTTP server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mpublic_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mngrok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublic_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" * ngrok tunnel \\\"{}\\\" -> \\\"http://127.0.0.1:{}\\\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpublic_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(addr, proto, name, pyngrok_config, **options)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating tunnel with options: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     tunnel = NgrokTunnel(api_request(\"{}/api/tunnels\".format(api_url), method=\"POST\", data=options,\n\u001b[0m\u001b[1;32m    272\u001b[0m                                      timeout=pyngrok_config.request_timeout),\n\u001b[1;32m    273\u001b[0m                          pyngrok_config, api_url)\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(url, method, data, params, timeout)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Response {}: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         raise PyngrokNgrokHTTPError(\"ngrok client exception, API returned {}: {}\".format(status_code, response_data),\n\u001b[0m\u001b[1;32m    478\u001b[0m                                     \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m                                     status_code, e.msg, e.hdrs, response_data)\n","\u001b[0;31mPyngrokNgrokHTTPError\u001b[0m: ngrok client exception, API returned 502: {\"error_code\":103,\"status_code\":502,\"msg\":\"failed to start tunnel\",\"details\":{\"err\":\"EOF\"}}\n"]}],"source":["import os\n","import threading\n","\n","from flask import Flask\n","from pyngrok import ngrok\n","\n","os.environ[\"FLASK_ENV\"] = \"development\"\n","\n","app = Flask(__name__)\n","port = 5000\n","\n","# Open a ngrok tunnel to the HTTP server\n","public_url = ngrok.connect(port).public_url\n","print(\" * ngrok tunnel \\\"{}\\\" -> \\\"http://127.0.0.1:{}\\\"\".format(public_url, port))\n","\n","# Update any base URLs to use the public ngrok URL\n","app.config[\"BASE_URL\"] = public_url\n","\n","# ... Update inbound traffic via APIs to use the public-facing ngrok URL\n","\n","\n","# Define Flask routes\n","@app.route(\"/\")\n","def index():\n","    return \"Hello from Colab!\"\n","\n","# Start the Flask server in a new thread\n","threading.Thread(target=app.run, kwargs={\"use_reloader\": False}).start()"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.11.0 64-bit (microsoft store)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.0"},"vscode":{"interpreter":{"hash":"5a31397678931673686870c6bd4cf7e66950272a38fd36a57785751fddc5beaa"}}},"nbformat":4,"nbformat_minor":0}